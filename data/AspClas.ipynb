{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf8\n",
    "import os\n",
    "from PIL import  Image\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch as t\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于Attention-based LSTM<br>\n",
    "每组数据需要<br>\n",
    "word representation $w_{1}, w_{2}, ..., w_{N}$<br>\n",
    "aspect embedding $v_{\\alpha}$<br>\n",
    "polarity $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-de8becd245f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mAspClas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedrt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         '''\n\u001b[0;32m      5\u001b[0m         \u001b[0m主要目标\u001b[0m\u001b[0;31m：\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "class AspClas(data.Dataset):\n",
    "    \n",
    "    def __init__(self, root, embedrt, transforms=None, train=True, test=False):\n",
    "        '''\n",
    "        主要目标：\n",
    "        载入文件 解析数据\n",
    "        根据 训练、验证、测试 划分数据\n",
    "        '''\n",
    "        self.raw_cases = []\n",
    "        self.cases = []\n",
    "        \n",
    "        # root = 'restaurants-trial.xml'\n",
    "        xml = ET.parse(root)\n",
    "        for s in xml.findall('sentence'):\n",
    "            if s.find('aspectTerms'):\n",
    "                text = s.find('text').text\n",
    "                asps = s.find('aspectTerms').findall('aspectTerm')\n",
    "                for asp in asps:\n",
    "                    self.raw_cases.append((text, asp.attrib['term'], asp.attrib['polarity']))\n",
    "        \n",
    "        # shuffle\n",
    "        np.random.seed(100)\n",
    "        self.raw_cases = np.random.permutation(self.raw_cases)\n",
    "        \n",
    "        # division\n",
    "        if test:\n",
    "            pass\n",
    "        elif train:\n",
    "            self.raw_cases = self.raw_cases[:int(0.7*len(self.raw_cases))]\n",
    "        else:\n",
    "            self.raw_cases = self.raw_cases[int(0.7*len(self.raw_cases)):]\n",
    "        \n",
    "        # transform\n",
    "        self.embedding(embedrt)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        一次返回一个 sentence-term-polarity\n",
    "        '''\n",
    "        case = self.cases[index]\n",
    "        return case[0], case[1], case[2]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cases)\n",
    "    \n",
    "    def embedding(self, root):\n",
    "        '''\n",
    "        transform the strings into vectors using pre-trained word vectors\n",
    "        '''\n",
    "        \n",
    "        # load file and init dict\n",
    "        self.embed = {}\n",
    "        self.embed['not found'] = t.Tensor(np.zeros(300), dtype=float)\n",
    "        \n",
    "        # root = 'glove.840B.300d/glove.840B.300d.txt'\n",
    "        f = open(root, 'r')\n",
    "        l = f.readline()\n",
    "        while(l != ''):\n",
    "            if l [-1] == '\\n':\n",
    "                l = l[:-1]\n",
    "            l = l.split(' ')\n",
    "            self.embed[l[0]] = t.Tensor(np.array(l[1:], dtype=float))\n",
    "            l = f.readline()\n",
    "        \n",
    "        embedks = self.embed.keys()\n",
    "        self.cases = []\n",
    "        self.polar = {'positive':1, 'neutral':0, 'negative':-1}\n",
    "        \n",
    "        # convert the strings in self.raw_cases into tensors\n",
    "        for (raw_text, raw_term, raw_polarity) in self.raw_cases:\n",
    "            # text\n",
    "            raw_words = word_tokenize(raw_text)\n",
    "            text = []\n",
    "            for rw in raw_words:\n",
    "                w = self.embed[rw] if rw in embedks else self.embed['not found']\n",
    "                text.append(w)\n",
    "            # term\n",
    "            term = self.embed[raw_term] if raw_term in embedks else self.embed['not found']\n",
    "            # polarity\n",
    "            polarity = self.polar[raw_polarity]\n",
    "            \n",
    "            self.cases.append((text, term, polarity))\n",
    "        self.raw_cases = []\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:\\\\Jupyter\\\\Python\\\\ATAE-LSTM')\n",
    "import Ipynb_importer\n",
    "from config import opt\n",
    "from Embedding import emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
